---
title: "AI Assistant for ML Forecast Explainability
Generative AI"
doc_type: "project"
tags: ["AI","GenAI","RAG","AWS Bedrock","Operations","Chatbot", "AWS Bedrock Chatbot", "GenAI Chatbot", AI Assistant]
timeframe: "2023-2026"
seniority: "Senior Product Leader"
language: "en"
source: "portfolio"
pii: "low"
---

## Summary

AskMe is a GenAI-powered chatbot built on AWS Bedrock that interprets ML forecast outputs for operational and planning teams. It provides role-based, explainable answers grounded in trusted data sources, reducing reliance on expert teams and accelerating decision-making from days to minutes.

## Problem

Operational and planning teams relied on the same ML forecasts but required very different explanations depending on their role. Accessing the right interpretation was slow, fragmented across dashboards and documentation, and heavily dependent on a small number of expertsâ€”creating bottlenecks, delays, and inconsistent decision-making.

## Context

AskMe was developed in a high-pressure operational environment where forecasting accuracy directly impacts capacity planning, staffing, and business performance. Multiple personas (operations managers, planning analysts, program managers) needed fast, reliable, and role-appropriate explanations of ML forecasts, all grounded in the same trusted data sources and governance rules.

## My Role

I acted as Product Lead and AI Product Owner, owning the solution end to end:

- Identified the core operational pain points and validated use cases with stakeholders
- Defined functional and non-functional requirements, including security, governance, and explainability
- Designed the user experience and role-based behavior of the chatbot
- Partnered with engineering and data teams to deliver a production-ready, serverless AI solution
- Oversaw rollout, feedback loops, and continuous improvement

## Decisions & Trade-offs

- **S3-based knowledge storage**: Chosen S3 storage over a database to keep the knowledge base simple, low-cost, versioned, and auditable for document-centric content, accepting limited query flexibility and higher retrieval latency compared to database-backed solutions.
- **Simple semantic search**: Chosen a brute force semantic similarity scoring with top-K selection for rapid delivery and a strong relevance baseline, accepting scalability limits and lower precision compared to hybrid, filtered, or reranked retrieval approaches.
- **Explanation over prediction**: Focused on interpreting existing ML outputs rather than building new models, maximizing adoption and trust
- **Role-based responses**: Accepted higher prompt and logic complexity to ensure each persona received actionable, relevant answers
- **Controlled autonomy**: Designed the chatbot as semi-autonomous, with explicit escalation paths to human experts to manage risk
- **Limited memory**: Chose short-lived session memory to reduce compliance and governance risks
- **Strict scope control**: Restricted problem categories and enforced refusals when data or confidence was insufficient

## Architecture

AskMe is a serverless, role-aware AI assistant integrated with internal forecasting knowledge:

- **Authentication & identity**: User email and role determine prompt configuration and response depth  
- **Prompt structure**: System instructions, business context (problem categories, rules, sources), and user query  
- **Knowledge storage**: Forecasting documentation and operational references stored in an S3-based knowledge base, enabling low-cost, versioned, and auditable content management  
- **RAG pipeline**: Brute-force semantic retrieval using precomputed embeddings to dynamically select the most relevant content and ground responses, reducing hallucinations  
- **Search strategy**: Cosine similarity scoring with top-K selection to balance relevance, simplicity, and performance for a controlled knowledge corpus  
- **Application logic**: Classifies question type, routes queries, and structures outputs consistently  
- **Auditability**: Logs requests, detected categories, and knowledge sources used for traceability and continuous improvement  
- **Feedback loop**: Users validate responses or escalate to experts, enabling iterative refinement of prompts, content, and retrieval logic  


## Outcomes / Metrics

- S3-based knowledge storage: Chose S3 storage over a database to keep the knowledge base simple, low-cost, versioned, and auditable for document-centric content, accepting limited query flexibility and higher retrieval latency compared to database-backed solutions.
- Simple semantic search: Started with brute-force semantic similarity and top-K selection for rapid delivery and a strong relevance baseline, accepting scalability limits and lower precision than hybrid, filtered, or reranked retrieval approaches.
- Reduced time to access reliable explanations from days to minutes
- Significantly decreased reliance on expert teams for repetitive investigations
- Improved consistency and confidence in forecast-driven decisions across teams
- Demonstrated how AI copilots can augment decision-makers directly within operational workflows

## What I'd Improve

- Introduce lightweight confidence scoring to make uncertainty more explicit
- Expand multilingual support for broader international teams
- Add proactive insights (e.g., anomaly detection alerts) rather than purely reactive Q&A
- Integrate deeper workflow actions (ticket creation, reporting) while preserving governance controls

## Keywords

GenAI, LLMs, RAG, AWS Bedrock, chatbot, ML explainability, operations support, role-based AI, serverless, forecasting, decision support, prompt engineering, BPMN, auditability, sentiment analysis